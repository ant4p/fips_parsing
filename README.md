### Парсер fips.ru ###

Для запуска - склонируйте проект командой git clone https://github.com/ant4p/fips_parsing.git <br/>
Создайте виртуальное окружение.<br/>
Установите в виртуальное окружение файл requirements.txt командой pip install -r requirements.txt<br/>
<br/>
Файл .env_example замените на .env c вашими данными: <br/>
-- не меняются --<br/>
BASE_URL="https://www.fips.ru/publication-web/classification/mpk" - основа для парсинга международной патентной классификации<br/>
EDITION='2025' - данные для GET запроса по году<br/>
-- меняются при необходимости --<br/>
FOLDER_WITH_JSON_PATH="json_files/" - папка в которой будут сохраняться json файлы, в корне проекта<br/>
FOLDER_WITH_XLSX_PATH = "xlsx_files/" - папка в которой будут сохраняться xlsx файлы, в корне проекта<br/>
OUTPUT_JSON_FILE="union.json" - название файла с конечным результатом<br/>
INPUT_MPK_FILENAME = "Подклассы МПК.xlsx" - файл с данными подклассов МПК<br/>
<br/>
Запустите проект в корневой папке командой python main.py<br/>
При текущих вводных данных, а именно поиск по 32ум подклассам МПК: время работы парсера около 47,5-48 секунд: из них 32 секунды - timeout между запросами, 15-16 секунд чистое время работы.<br/>
На выходе получаем папку с файлами json по каждому виду МПК, общий union.json, который создаётся в корне проекта<br/>
папку с файлнами xlsx c тремя вариантами представления данных, по сборным данным.<br/>
Все из созданных json и xlsx файлов имеют иерархическую структуру, и могут содержать многоуровневые вложенные подгруппы<br/>
<br/>

Описание програмного решения:<br/>
Процесс парсинга сайта fips.ru декомпозирован на задачи:<br/>
1. Выделить модули кода согласно логике, чтобы можно было их легко заменять или переиспользовать<br/>
Так в файлах:<br/>
parser_mpk.py - находится сам парсер<br/>
utils.py - находятся функции которые осуществляют обработку сырых дынных<br/>
script.py - находятся функции которые осуществляют обработку уже готовых данных полученных путём парсинга, при желании эти функции можно переписать на скрипты bash или powershell <br/>
convert_to_xlsx.py - находятся функции преобразования в xlsx файлы<br/>
main.py - основной файл проекта, точка входа, в котором весь процесс ETL данных собирается из модулей.
2. Получаем список МПК из файла, по которым будем осуществлять сбор информации<br/>
3. Используем парсер для получения сырых данных и сохранения их в датафрейме pandas проходясь по каждому элементу из полученного списка МПК<br/>
4. Сохраняем данные в json формате для каждого конкретного МПК в отдельной папке<br/>
5. Получаем список сохранённых json файлов и объединяем в один общий json файл<br/>
6. Преобразуем общий json файл в xlsx в 3ёх вариантах и сохраняем их в папке xlsx_files<br/>
7. Замеряем время работы всей сборки и выборочно проверяем полученные данные<br/>
8. При желании проверяем полученные данные на интерактивной диаграме plotly или древовидной структуре tree.html файла<br/>
<br/>
Во всех файлах есть комментарии объясняющие работу функции или обозначающих происходящие процессы<br/>
В корневом каталоге присутствует файл union_example.json - получившийся в результате объединения данных с разных json МПК<br/>
Так же в корневом каталоге присутствует папка json_files_example содержащая json файлы согласно МПК - получившаяся в результате парсинга<br/>
<br/>
Для того, чтобы наглядно проверить полученные данные в папке output присутствуют 2 html файла:<br/>
plotly.html - настроен на круговую иерархическую интерактивную диаграмму по файлу 'B63B.json' <br/>
соответственно вы можете воспользоваться им после парсинга<br/>
<br/>
<p align="center">
 <img width=auto height=1000 src="images/plotly_html_view.png" alt="coverage"/>
</p>
<br/>
<p align="center">
 <img width=auto height=1000 src="images/plotly_html_view_2.png" alt="coverage"/>
</p>
<br/>
tree.html - настроен на показ иерархической древовидной структура распарсеных данных из объединённого файла union.json, который соответственно будет доступен тоже после парсинга<br/>
<br/>
<p align="center">
 <img width=auto height=1000 src="images/tree_html_view.png" alt="coverage"/>
</p>
<br/>
Обе html страницы будут корректно работать на localhost при использовании Live Server.<br/>
<br/>
Для сервиса использованы:<br/>
python3.12 - ЯП<br/>
python-dotenv переменные окружения .env<br/>
bs4 - для извлечения данных<br/>
pandas - обработка данных<br/>
openpyxl - обработка данных для .xlsx файлов<br/>
plotly - интерактивная диаграмма через cdn<br/>
os, time, requests, json - стандартные python библиотеки<br/>
live server - для локального просмотра html страниц
<br/>
